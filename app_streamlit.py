# Importar librer√≠as 
import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import matplotlib.pyplot as plt
import numpy as np

from pyspark.sql.functions import mean, col, count, month, year, sum, hour, when
from src.lectura_gestiones import crear_spark, cargar_gestiones
from modelos.modelo_nlp import entrenar_modelo_nlp, limpiar_texto_udf
from modelos.pedidos.entrenar_pedidos import entrenar_modelos_pedidos
from modelos.pedidos.predictor_pedidos import predecir_pedido
from wordcloud import WordCloud, STOPWORDS
from datetime import date, timedelta

# -------------------------------
# CONFIGURACI√ìN GENERAL
# -------------------------------
st.set_page_config(
    page_title="Clasificaci√≥n de gestiones e impacto en colocaci√≥n de pedidos",
    page_icon="üìû",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Estilos CSS personalizados (opcional, puedes ajustarlo)
st.markdown("""
    <style>
    .main-header {
        font-size: 32px;
        font-weight: bold;
        margin-bottom: 0.5rem;
    }
    .sub-header {
        font-size: 24px;
        font-weight: bold;
        margin-top: 1rem;
        margin-bottom: 0.5rem;
    }
    </style>
""", unsafe_allow_html=True)

# -------------------------------
# FUNCIONES AUXILIARES
# -------------------------------
def grafica_conteo_porcentaje(df_spark, columna, titulo, key=None):
    """
    Genera una gr√°fica de barras con:
    - Eje Y: total de registros
    - Etiqueta: porcentaje (%)
    Y muestra tambi√©n la tabla con totales y porcentajes.

    key: identificador √∫nico para evitar conflictos de Streamlit.
    """
    total_registros = df_spark.count()

    df_group = (
        df_spark
        .groupBy(columna)
        .agg(count("*").alias("total"))
        .withColumn("porcentaje", (col("total") / total_registros * 100))
        .orderBy(col("total").desc())
    )

    pdf = df_group.toPandas()
    pdf["porcentaje_label"] = pdf["porcentaje"].round(2).astype(str) + "%"

    fig = px.bar(
        pdf,
        x=columna,
        y="total",
        text="porcentaje_label",
        title=titulo,
    )
    fig.update_traces(textposition="outside")
    fig.update_layout(
        yaxis_title="Total de registros",
        xaxis_title=columna,
        uniformtext_minsize=8,
        uniformtext_mode="hide"
    )

    st.plotly_chart(fig, use_container_width=True, key=key or f"plot_{columna}_{titulo}")
    st.dataframe(pdf)

def generar_nube_palabras(df_spark, etiqueta, max_words=100):
    # Usa la columna limpia si existe
    col_texto = "nota_clean" if "nota_clean" in df_spark.columns else "nota"

    notas_pd = (
        df_spark
        .filter(col("resultado_asesor") == etiqueta)
        .select(col_texto)
        .toPandas()
    )

    if notas_pd.empty:
        return None

    texto = " ".join(notas_pd[col_texto].astype(str).tolist())

    stopwords = set(STOPWORDS)
    stopwords.update({
        "cliente", "llamada", "whatsapp", "asesor", "gestion", "gestiones",
        "producto", "productos", "servicio", "servicios", "oferta",
        "paquete", "informacion", "informaci√≥n", "mas", "m√°s",
        "dijo", "coment√≥", "comento", "menciono", "mencion√≥",
        "indico", "indic√≥", "pidio", "pidi√≥", "mostro", "mostr√≥",
        "que", "de", "la", "el", "los", "las", "en", "por", "para",
        "interes", "interesado", "interesada", "interesados",
        "interesarse", "interesar",
    })

    wc = WordCloud(
        width=800,
        height=400,
        background_color="white",
        max_words=max_words,
        stopwords=stopwords
    ).generate(texto)

    fig, ax = plt.subplots(figsize=(8, 4))
    ax.imshow(wc, interpolation="bilinear")
    ax.axis("off")
    plt.tight_layout()
    return fig

# -------------------------------
# CARGAR DATOS
# -------------------------------
RUTA_CSV = "datos/gestiones.csv"

@st.cache_resource
def get_spark():
    return crear_spark()

@st.cache_resource
def get_data():
    spark = get_spark()
    df = cargar_gestiones(spark, RUTA_CSV)
    # Crear columna de nota limpia (para modelo y nubes de palabras)
    if "nota_clean" not in df.columns:
        df = df.withColumn("nota_clean", limpiar_texto_udf(col("nota")))
    return df

df = get_data()

# -------------------------------
# SIDEBAR (RADIO DE P√ÅGINAS)
# -------------------------------
st.sidebar.info("""
**üìö Sistema de an√°lisis y predicci√≥n de gestiones para mejorar la colocaci√≥n de pedidos en categor√≠as de conectividad, hogar y movilidad**

Universidad An√°huac Puebla  
üìö Ciencia de Datos            

Alumna: Karla Beatriz Hern√°ndez Castro 
                
""")

st.sidebar.markdown("---")

st.sidebar.markdown("### üìå Selecciona una secci√≥n")
page = st.sidebar.radio(
    "Selecciona una secci√≥n:",
    [
        "üè† Inicio",
        "üìà An√°lisis Exploratorio de Gestiones y Pedidos",
        "ü§ñ Modelo: Clasificaci√≥n de Notas de Gestiones",
        "üìä Modelo: Predicci√≥n de Horario de Gestiones para Mayor Efectividad de Pedidos",
        "üìù Conclusiones",
    ],
    label_visibility="collapsed"
)

# ===============================
# P√ÅGINA: üè† INICIO
# ===============================
if page == "üè† Inicio":
    st.markdown(
        """
        <h2 class="sub-header">
            ü§ñüìà Sistema de An√°lisis y Predicci√≥n de Gestiones para Mejorar la venta 
            de pedidos en diferentes categor√≠as.üîÆ
        </h2>
        """,
        unsafe_allow_html=True
    )
    st.markdown('<h3>Descripci√≥n de proyecto</h3>', unsafe_allow_html=True)

    st.markdown("""
    El sistema analiza todas las gestiones realizadas por asesores durante 2025 para comprender
    c√≥mo responden los clientes y qu√© tan probable es que finalicen en una compra.

    Adem√°s, incluye un modelo que recomienda **el mejor horario para contactar al cliente**,
    basado en patrones de comportamiento y la informaci√≥n registrada en la nota del asesor,
    buscando aumentar la efectividad de cada gesti√≥n.
    """)

    # Prop√≥sito, reglas y problema a resolver
    st.markdown("""
    ---
    ### üéØ Prop√≥sito del sistema: 

    Este proyecto nace para responder tres preguntas: 
    
    1. **¬øC√≥mo es el desempe√±o comercial de los asesores actualmente?**
                
    2. **¬øLas notas del asesor reflejan si el cliente est√° interesado o no en realizar un pedido?**  

    3. **¬øEn qu√© horario es mejor realizar una gesti√≥n para que el cliente compre?**  
                
    ---

    ### üß© Datos a analizar

    - Se cuenta con un dataset en formato CSV que contiene el resultado de la extracci√≥n y transformaci√≥n de los datos de gestiones 
      realizadas en el a√±o 2025. 
                
      El origen de este archivo es la uni√≥n de gestiones vs pedidos generados en un lapso de 24 horas por lo que se asume que se realiz√≥ 
      la compra por este motivo. 
    """)
    #SCHEMA
    st.subheader("üîé Tipos de datos")
    st.caption(
        "Informaci√≥n por columna de lo que se espera recibir en cada columna del archivo para realizar el an√°lisis"
    )
    columnas_info = [
        {
            "columna": "id_gestion",
            "tipo_dato": "int",
            "descripcion": "Identificador √∫nico de cada gesti√≥n (registro en la base).",
            "valores_esperados": "Enteros consecutivos, sin duplicados."
        },
        {
            "columna": "id_cliente",
            "tipo_dato": "string",
            "descripcion": "Identificador del cliente al que se le realiz√≥ la gesti√≥n.",
            "valores_esperados": "Formato 'C#########', puede repetirse (un cliente con varias gestiones)."
        },
        {
            "columna": "id_asesor",
            "tipo_dato": "string",
            "descripcion": "Identificador del asesor que realiz√≥ la gesti√≥n.",
            "valores_esperados": "Formato 'A#########', un asesor puede aparecer en muchas gestiones."
        },
        {
            "columna": "medio",
            "tipo_dato": "string (categ√≥rica)",
            "descripcion": "Canal por el cual se realiz√≥ la gesti√≥n.",
            "valores_esperados": "'llamada' o 'whatsapp'."
        },
        {
            "columna": "resultado_asesor",
            "tipo_dato": "string (categ√≥rica)",
            "descripcion": "Evaluaci√≥n del asesor sobre el inter√©s del cliente.",
            "valores_esperados": "'interesado' o 'no_interesado'."
        },
        {
            "columna": "fecha_hora",
            "tipo_dato": "timestamp",
            "descripcion": "Fecha y hora en la que se realiz√≥ la gesti√≥n.",
            "valores_esperados": "Timestamps entre 2025-01-01 y 2025-12-31 aprox."
        },
        {
            "columna": "nota",
            "tipo_dato": "string (texto libre)",
            "descripcion": "Comentario del asesor sobre la gesti√≥n; base para el modelo NLP.",
            "valores_esperados": "Frases en espa√±ol que describen la respuesta del cliente y contexto."
        },
        {
            "columna": "pedido_generado",
            "tipo_dato": "int (0/1)",
            "descripcion": "Indica si la gesti√≥n termin√≥ en un pedido.",
            "valores_esperados": "0 = no gener√≥ pedido, 1 = s√≠ gener√≥ pedido."
        },
        {
            "columna": "id_pedido",
            "tipo_dato": "string",
            "descripcion": "Identificador del pedido generado a partir de la gesti√≥n (si aplica).",
            "valores_esperados": "Formato 'P#########' cuando pedido_generado=1, 'NA' cuando pedido_generado=0."
        },
        {
            "columna": "monto_pedido",
            "tipo_dato": "double",
            "descripcion": "Monto total del pedido asociado a la gesti√≥n.",
            "valores_esperados": "0 si no hubo pedido; entre ~200 y 35,000 cuando pedido_generado=1."
        },
        {
            "columna": "producto_categoria",
            "tipo_dato": "string (categ√≥rica)",
            "descripcion": "Tipo de producto asociado al pedido.",
            "valores_esperados": "'conectividad', 'movilidad', 'hogar' cuando hay pedido; 'NA' cuando no hay pedido."
        },
    ]

    tipos_df = pd.DataFrame(columnas_info)
    st.dataframe(tipos_df, use_container_width=True)

    # Revisi√≥n de nulos
    st.subheader("üßº Limpieza de datos antes de an√°lisis")
    st.caption(
        "Se verifica si hay valores faltantes en alguna columna que puedan afectar el entrenamiento de los modelos."
    )

    nulos_pd = df.select([
        sum(col(c).isNull().cast("int")).alias(c)
        for c in df.columns
    ]).toPandas().T.reset_index()

    nulos_pd.columns = ["columna", "n_nulos"]
    st.dataframe(nulos_pd)

    # Validaci√≥n l√≥gica de reglas
    st.subheader("‚úÖ Validaci√≥n de datos")
    st.caption("Se verifica la coherencia entre los pedidos y categor√≠as para revisar que el archivo se gener√≥ correctamente")

    regla1 = df.filter((df.pedido_generado == 1) & (df.id_pedido == "NA")).count()
    regla2 = df.filter((df.pedido_generado == 0) & (df.monto_pedido != 0)).count()
    regla3 = df.filter((df.pedido_generado == 0) & (df.producto_categoria != "NA")).count()

    c1, c2, c3 = st.columns(3)
    c1.metric("Pedidos que no cuentan con n√∫mero de pedio", regla1)
    c2.metric("Sin pedido pero con monto mayor a $0", regla2)
    c3.metric("Sin pedido pero con alguna categor√≠a de hogar, movilidad o conectividad", regla3)

    # Muestra de datos
    st.subheader("üîé Muestra de datos")
    st.caption(
        "Muestra representativa de la base para revisar visualmente los campos y el tipo de informaci√≥n registrada."
    )
    muestra = df.limit(1000).toPandas()
    st.dataframe(muestra)
    
    st.markdown("---")

# ===============================
# P√ÅGINA: üìà An√°lisis Exploratorio de Gestiones y Pedidos
# ===============================
elif page == "üìà An√°lisis Exploratorio de Gestiones y Pedidos":
    st.subheader("üìà An√°lisis Exploratorio de Gestiones y Pedidos detallado")
    st.subheader("""¬øC√≥mo es el desempe√±o comercial de los asesores actualmente?""")
    st.markdown(
        "En esta secci√≥n se revisar√° el estatus actual de las gestiones y pedidos generado de los asesores durante el 2025"
    )   
    st.markdown("---")


    st.markdown(
        "Informaci√≥n general de la base de datos: "
    )
    # KPIs b√°sicos
    total_registros = df.count()
    tasa_pedidos = df.select(mean("pedido_generado").alias("tasa")).collect()[0]["tasa"]

    # Total de pedidos generados
    total_pedidos = df.filter(col("pedido_generado") == 1).count()

    # Total de pedidos NO generados
    total_no_pedidos = df.filter(col("pedido_generado") == 0).count()

    # Tasa de pedidos NO generados
    tasa_no_pedidos = total_no_pedidos / total_registros

    col1, col2, col3 = st.columns(3)
    col1.metric("Total de gestiones realizadas en 2025", f"{total_registros:,}")
    col2.metric("Total de pedidos generados", f"{tasa_pedidos*100:.2f}%")
    col3.metric("Total de pedidos NO generados", f"{tasa_no_pedidos*100:.2f}%")

    st.info("Por 1,000,000 de gestiones solo el 40% generan un pedido")


    st.markdown("---")

    st.subheader("**üìÜ ¬øC√≥mo vamos en las ventas por mes?**")

    df_mes = (
        df
        .withColumn("anio", year(col("fecha_hora")))
        .withColumn("mes", month(col("fecha_hora")))
    )

    df_gestiones = (
        df_mes.groupBy("anio", "mes")
        .count()
        .withColumnRenamed("count", "total_gestiones")
    )

    df_pedidos = (
        df_mes.groupBy("anio", "mes")
        .agg(sum(col("pedido_generado")).alias("total_pedidos"))
    )

    df_join = (
        df_gestiones.join(df_pedidos, ["anio", "mes"], "inner")
        .orderBy("anio", "mes")
    )

    pdf = df_join.toPandas()
    pdf["mes_str"] = pdf["anio"].astype(str) + "-" + pdf["mes"].astype(str).str.zfill(2)

    fig = go.Figure()
    fig.add_trace(go.Bar(
        x=pdf["mes_str"],
        y=pdf["total_gestiones"],
        name="Gestiones",
        marker=dict(color="royalblue",opacity=0.7)
    ))
    fig.add_trace(go.Scatter(
        x=pdf["mes_str"],
        y=pdf["total_pedidos"],
        name="Pedidos generados",
        mode="lines+markers",
        line=dict(width=3, color="#00FF7F")
    ))
    fig.update_layout(
        title="Gestiones totales vs pedidos generados por mes",
        xaxis_title="Mes",
        yaxis_title="Cantidad",
        barmode="group"
    )

    st.plotly_chart(fig, use_container_width=True)
    st.dataframe(pdf)

    st.info("El mes de mayo tiene el mayor n√∫mero de pedidos generados aunque no es el mes con mayor gestiones realizadas")

    st.subheader("üìÜ ¬øC√≥mo se comporta el inter√©s del cliente por mes?")

    # Agregar columnas de a√±o y mes
    df_mes_int = (
        df
        .withColumn("anio", year(col("fecha_hora")))
        .withColumn("mes", month(col("fecha_hora")))
    )

    # Conteo de interesados y no interesados por mes
    df_interes = (
        df_mes_int.groupBy("anio", "mes")
        .agg(
            sum(when(col("resultado_asesor") == "interesado", 1).otherwise(0)).alias("interesado"),
            sum(when(col("resultado_asesor") == "no_interesado", 1).otherwise(0)).alias("no_interesado")
        )
        .orderBy("anio", "mes")
    )

    pdf_int = df_interes.toPandas()
    pdf_int["mes_str"] = pdf_int["anio"].astype(str) + "-" + pdf_int["mes"].astype(str).str.zfill(2)

    # --- Gr√°fica ---
    fig_int = go.Figure()

    # Barras ‚Äì interesados
    fig_int.add_trace(go.Bar(
        x=pdf_int["mes_str"],
        y=pdf_int["interesado"],
        name="Interesado",
        marker=dict(color="royalblue", opacity=0.8)
    ))

    # L√≠nea ‚Äì no interesados
    fig_int.add_trace(go.Scatter(
        x=pdf_int["mes_str"],
        y=pdf_int["no_interesado"],
        name="No interesado",
        mode="lines+markers",
        line=dict(width=3, color="crimson")
    ))

    fig_int.update_layout(
        title="Interesados vs No interesados por mes",
        xaxis_title="Mes",
        yaxis_title="Cantidad",
        barmode="group",
        template="plotly_white"
    )

    st.plotly_chart(fig_int, use_container_width=True)
    st.dataframe(pdf_int)

    st.info("El mes de Octubre es cuando m√°s gente no se ha interesado en adquirir un producto. " \
    "Adicional a que la tendencia indica que existe mayor cantidad de personas no interesadas que interesadas")

    st.subheader("üìûüì¶ ¬øQu√© combinaci√≥n de medio y categor√≠a genera m√°s pedidos?")

    # 1) Nos quedamos s√≥lo con los registros que S√ç generaron pedido
    df_med_cat = (
        df.filter(col("pedido_generado") == 1)
        .groupBy("medio", "producto_categoria")
        .agg(
            count("*").alias("pedidos")
        )
    )

    pdf_med_cat = df_med_cat.toPandas()

    # Si hubiera nulos en producto_categoria, los marcamos como 'sin_categoria'
    pdf_med_cat["producto_categoria"] = (
        pdf_med_cat["producto_categoria"].fillna("sin_categoria")
    )

    # Podemos excluir 'sin_categoria' si no quieres verla en el gr√°fico
    pdf_med_cat = pdf_med_cat[pdf_med_cat["producto_categoria"] != "sin_categoria"]

    # 2) Total de pedidos por medio (para calcular % dentro de cada canal)
    pdf_med_cat["total_pedidos_medio"] = (
        pdf_med_cat.groupby("medio")["pedidos"].transform("sum")
    )

    pdf_med_cat["porc_pedidos_medio"] = (
        (pdf_med_cat["pedidos"] / pdf_med_cat["total_pedidos_medio"]) * 100
    ).round(2)

    # 3) Gr√°fico de barras: pedidos por medio √ó categor√≠a
    fig_mc = px.bar(
        pdf_med_cat,
        x="producto_categoria",
        y="pedidos",
        color="medio",
        barmode="group",
        text=pdf_med_cat["porc_pedidos_medio"].astype(str) + "%",
        title="Pedidos generados por combinaci√≥n Medio √ó Categor√≠a",
        labels={
            "pedidos": "Pedidos generados",
            "producto_categoria": "Categor√≠a de producto"
        },
    )

    fig_mc.update_traces(textposition="outside")
    fig_mc.update_layout(
        yaxis_title="N√∫mero de pedidos",
        xaxis_title="Categor√≠a de producto",
    )

    st.plotly_chart(fig_mc, use_container_width=True)

    st.markdown("### üìã Resumen Medio √ó Categor√≠a")
    st.dataframe(
        pdf_med_cat[[
            "medio",
            "producto_categoria",
            "pedidos",
            "total_pedidos_medio",
            "porc_pedidos_medio",
        ]],
        use_container_width=True
    )

    st.info("Es mejor realizar una llamada que un mensaje de Whatsapp para cualquier categoria")
    

    st.markdown("---")
    st.subheader("üèÜ Top 10 asesores por pedidos generados")

    df_pedidos = (
        df.groupBy("id_asesor")
        .agg(sum(col("pedido_generado")).alias("total_pedidos"))
    )
    df_gestiones = (
        df.groupBy("id_asesor")
        .count()
        .withColumnRenamed("count", "total_gestiones")
    )
    df_asesores = (
        df_pedidos.join(df_gestiones, "id_asesor", "inner")
        .orderBy(col("total_pedidos").desc())
        .limit(10)
    )

    pdf_top = df_asesores.toPandas()

    fig = go.Figure()
    fig.add_trace(go.Bar(
        x=pdf_top["id_asesor"],
        y=pdf_top["total_pedidos"],
        name="Pedidos",
    ))
    fig.add_trace(go.Bar(
        x=pdf_top["id_asesor"],
        y=pdf_top["total_gestiones"],
        name="Gestiones",
        opacity=0.6
    ))
    fig.update_layout(
        title="Top 10 asesores por pedidos y gestiones",
        xaxis_title="ID Asesor",
        yaxis_title="Cantidad",
        barmode="group"
    )

    st.plotly_chart(fig, use_container_width=True, key="plot_top10_asesores")
    st.dataframe(pdf_top)


    st.subheader("üö® Bottom 10 asesores con menos pedidos generados")

    df_pedidos = (
        df.groupBy("id_asesor")
        .agg(sum(col("pedido_generado")).alias("total_pedidos"))
    )
    df_gestiones = (
        df.groupBy("id_asesor")
        .count()
        .withColumnRenamed("count", "total_gestiones")
    )
    df_asesores_bottom = (
        df_pedidos.join(df_gestiones, "id_asesor", "inner")
        .orderBy(col("total_pedidos").asc())
        .limit(10)
    )

    pdf_bottom = df_asesores_bottom.toPandas()

    fig = go.Figure()
    fig.add_trace(go.Bar(
        x=pdf_bottom["id_asesor"],
        y=pdf_bottom["total_pedidos"],
        name="Pedidos",
        marker=dict(color="crimson")
    ))
    fig.add_trace(go.Bar(
        x=pdf_bottom["id_asesor"],
        y=pdf_bottom["total_gestiones"],
        name="Gestiones",
        opacity=0.6,
        marker=dict(color="gray")
    ))
    fig.update_layout(
        title="Bottom 10 asesores: menos pedidos y sus gestiones",
        xaxis_title="ID Asesor",
        yaxis_title="Cantidad",
        barmode="group"
    )

    st.plotly_chart(fig, use_container_width=True, key="plot_bottom10_asesores")
    st.dataframe(pdf_bottom)


# ===============================
# P√ÅGINA: ü§ñ NLP
# ===============================
elif page == "ü§ñ Modelo: Clasificaci√≥n de Notas de Gestiones":
    st.title("üß† ¬øLas notas del asesor reflejan si el cliente est√° interesado o no en realizar un pedido?")

    st.markdown("""
    Prop√≥sito de la pregunta: 
    """)

    st.markdown("""
    Conocer a partir de t√©cnicas de **Procesamiento de Lenguaje Natural (NLP)** si la nota que escribe el asesor en cada gesti√≥n coincide 
    con el resultado que √©l asigna en los rubros de **"INTERESADO o NO INTERESADO"**:
    """)
                
    st.markdown("---")
    st.subheader("üöÄ Entrenamiento del modelo NLP")
    st.caption("""
    üß† Modelo NLP: Clasificaci√≥n de notas de gestiones <br>
    1. Limpieza de texto: se normaliza la nota (nota_clean: min√∫sculas, sin acentos ni signos raros). <br>
    2. Tokenizaci√≥n: se separa la nota en palabras (tokens). <br>
    3. Eliminaci√≥n de stopwords: e quitan palabras muy comunes que no aportan significado. <br>
    4. Vectorizaci√≥n TF-IDF: se convierte el texto a n√∫meros con (TF-IDF mide qu√© tan importante es una palabra dentro de un texto, compar√°ndola con todos los textos del dataset). <br>
    5. Entrenamiento: entrena una Regresi√≥n Log√≠stica para predecir resultado_asesor (interesado / no_interesado). <br>
    6. Evaluaci√≥n: e calcula Accuracy y F1-score y se arma la matriz de confusi√≥n para los datos de prueba.<br>
    """, unsafe_allow_html=True)

    if st.button("Entrenar modelo NLP (Regresi√≥n Log√≠stica)", type="primary"):
        with st.spinner("Entrenando modelo NLP sobre notas de gestiones, por favor espera..."):
            metrics, confusion_df_spark, modelo_nlp = entrenar_modelo_nlp(df)

        labels = metrics["labels"]
        confusion_pdf = confusion_df_spark.toPandas()

        def decode_label(idx):
            try:
                return labels[int(idx)]
            except Exception:
                return str(idx)

        confusion_pdf["label_str"] = confusion_pdf["label"].apply(decode_label)
        confusion_pdf["prediction_str"] = confusion_pdf["prediction"].apply(decode_label)
        confusion_pdf = confusion_pdf[["label_str", "prediction_str", "count"]]
        confusion_pdf = confusion_pdf.rename(columns={
            "label_str": "Etiqueta real (resultado_asesor)",
            "prediction_str": "Predicci√≥n modelo",
            "count": "Cantidad"
        })

        st.session_state["modelo_nlp"] = modelo_nlp
        st.session_state["labels_nlp"] = labels
        st.session_state["metrics_nlp"] = metrics
        st.session_state["confusion_pdf_nlp"] = confusion_pdf

        st.success("‚úÖ Entrenamiento completado correctamente.")

    if "metrics_nlp" in st.session_state:

        metrics = st.session_state["metrics_nlp"]
        confusion_pdf = st.session_state["confusion_pdf_nlp"]
        labels = st.session_state["labels_nlp"]

        acc = metrics["accuracy"]
        f1 = metrics["f1"]
        num_train = metrics["num_train"]
        num_test = metrics["num_test"]

        col1, col2, col3 = st.columns(3)
        col1.metric("Accuracy (¬øQu√© tantas notas clasifica bien el modelo?)", f"{acc*100:.2f}%")
        col2.metric("F1-score (¬øQu√© tan equilibrada es la calidad de la clasificaci√≥n?)", f"{f1:.3f}")
        col3.metric("Registros (train/test)", f"{num_train} / {num_test}")

        st.markdown("### üîÅ Matriz de confusi√≥n para datos test")
        st.dataframe(confusion_pdf)

        cm_pivot = confusion_pdf.pivot(
            index="Etiqueta real (resultado_asesor)",
            columns="Predicci√≥n modelo",
            values="Cantidad"
        ).fillna(0)

        fig_cm = px.imshow(
            cm_pivot,
            text_auto=True,
            color_continuous_scale="Blues",
            labels=dict(
                x="Predicci√≥n del modelo",
                y="Etiqueta real (resultado_asesor)",
                color="Cantidad"
            ),
            title="Matriz de confusi√≥n - modelo NLP (Regresi√≥n Log√≠stica)"
        )
        fig_cm.update_layout(xaxis_side="top")
        st.plotly_chart(fig_cm, use_container_width=True, key="cm_heatmap_nlp")

        st.markdown(
            "<p style='font-size: 0.85rem; color: gray;'>"
            "La matriz de confusi√≥n permite analizar d√≥nde el modelo acierta m√°s y en qu√© casos se confunde.<br>"
            "‚Ä¢ El modelo identifica correctamente a la mayor√≠a de los clientes no interesados (m√°s de 108 mil casos bien clasificados).<br>"
            "‚Ä¢ Tambi√©n clasifica de forma precisa a los clientes interesados, con m√°s de 76 mil aciertos.<br>"
            "‚Ä¢ Los errores (falsos positivos y falsos negativos) son relativamente bajos comparados con el volumen total.<br>"
            "</p>",
            unsafe_allow_html=True
        )

        # SECCI√ìN DE NUBES 
        st.markdown("---")
        st.subheader("‚òÅÔ∏è Nube de palabras: interesado vs no_interesado")

        col_int, col_no = st.columns(2)

        # 1) Nube 'interesado' (solo se genera una vez)
        if "wordcloud_interesado" not in st.session_state:
            with st.spinner("Generando nube de palabras para 'interesado'..."):
                fig_int = generar_nube_palabras(df, "interesado", max_words=80)
                st.session_state["wordcloud_interesado"] = fig_int

        with col_int:
            st.markdown("**Notas con resultado_asesor = 'interesado'**")
            if st.session_state["wordcloud_interesado"] is not None:
                st.pyplot(st.session_state["wordcloud_interesado"], use_container_width=True)
            else:
                st.info("No hay suficientes notas para 'interesado'.")

        # 2) Nube 'no_interesado' (solo se genera una vez)
        if "wordcloud_no_interesado" not in st.session_state:
            with st.spinner("Generando nube de palabras para 'no_interesado'..."):
                fig_no = generar_nube_palabras(df, "no_interesado", max_words=80)
                st.session_state["wordcloud_no_interesado"] = fig_no

        with col_no:
            st.markdown("**Notas con resultado_asesor = 'no_interesado'**")
            if st.session_state["wordcloud_no_interesado"] is not None:
                st.pyplot(st.session_state["wordcloud_no_interesado"], use_container_width=True)
            else:
                st.info("No hay suficientes notas para 'no_interesado'.")
                
        # PRUEBA EN VIVO NLP
        st.markdown("---")
        st.subheader("‚úçÔ∏è Prueba en vivo del modelo NLP")

        st.caption("Escribe una nota y el modelo te dir√° si suena a 'interesado' o 'no_interesado'.")

        nota_input = st.text_area(
            "Escribe aqu√≠ la nota del asesor:",
            height=120,
            placeholder="Ejemplo: El cliente pidi√≥ m√°s informaci√≥n sobre el paquete de internet..."
        )

        if st.button("Clasificar nota con el modelo NLP"):
            if "modelo_nlp" not in st.session_state:
                st.error("Primero entrena el modelo NLP con el bot√≥n de arriba.")
            elif not nota_input.strip():
                st.error("Por favor escribe una nota antes de clasificar.")
            else:
                spark = get_spark()

                # 1) Crear DataFrame con la nota original
                df_nota = spark.createDataFrame(
                    [(nota_input, "interesado")],  # etiqueta dummy
                    ["nota", "resultado_asesor"]
                )

                # 2) Generar la columna esperada por el pipeline
                # usar limpiar_texto_udf (tu funci√≥n real)
                df_nota = df_nota.withColumn("nota_clean", limpiar_texto_udf(col("nota")))

                # 3) Recuperar modelo y labels
                modelo = st.session_state["modelo_nlp"]
                labels = st.session_state["labels_nlp"]

                # 4) Transformar y obtener predicci√≥n
                pred_row = (
                    modelo.transform(df_nota)
                        .select("prediction", "probability")
                        .collect()[0]
                )

                pred_idx = int(pred_row["prediction"])
                probs = pred_row["probability"].toArray().tolist()

                etiqueta_pred = labels[pred_idx]
                prob_pred = probs[pred_idx]

                # Mostrar resultados
                st.success(f"Predicci√≥n: **{etiqueta_pred}**")
                st.metric("Confianza del modelo", f"{prob_pred*100:.2f}%")

                df_probs = pd.DataFrame({
                    "clase": labels,
                    "probabilidad": probs
                }).sort_values("probabilidad", ascending=False)

                st.markdown("#### Detalle de probabilidades por clase")
                st.dataframe(df_probs)

    else:
        st.warning("Pulsa el bot√≥n para entrenar el modelo NLP con las notas de gesti√≥n.")



# ===============================
# P√ÅGINA: üìä Modelo: Predicci√≥n de Horario de Gestiones para Mayor Efectividad de Pedidos (SOLO MODELO)
# ===============================
elif page == "üìä Modelo: Predicci√≥n de Horario de Gestiones para Mayor Efectividad de Pedidos":
    st.title("üìä ¬øEn qu√© horario es mejor realizar una gesti√≥n para que el cliente compre?")

    st.markdown("""
    Para saber el mejor horario para realizar una gesti√≥n que termine en un pedido generado es necesario considerar 
    - Medio de contacto (`medio`)
    - Resultado del asesor (`resultado_asesor`)
    - Momento de la gesti√≥n (`fecha_hora` ‚Üí hora de la gesti√≥n)
    """)

    df = get_data()

    st.markdown("---")
    st.subheader("üöÄ Entrenamiento del modelo para predicci√≥n de pedidos")


    st.caption("""
    üìä Modelo de predicci√≥n de pedidos: mejor horario <br>
    1. Selecci√≥n de variables: medio, resultado_asesor y fecha_hora. <br>
    2. Preparaci√≥n de datos: codificaci√≥n y features num√©ricos. <br>
    3. Divisi√≥n train/test. <br>
    4. Entrenamiento con Regresi√≥n Log√≠stica. <br>
    5. Evaluaci√≥n: Accuracy, F1, Precisi√≥n, Recall, AUC y matriz de confusi√≥n. <br>
    6. Predicci√≥n en vivo. <br>
    7. Recomendaci√≥n de horario simulando horas 09‚Äì21. <br>
    """, unsafe_allow_html=True)
    
    if st.button("Entrenar modelo de predicci√≥n de pedidos (Regresi√≥n Log√≠stica)", type="primary"):
        with st.spinner("Entrenando modelo de predicci√≥n de pedidos (Regresi√≥n Log√≠stica)..."):
            resultados_pedidos, pipeline_model, lr_model = entrenar_modelos_pedidos(df)

        st.session_state["pedidos_resultados"] = resultados_pedidos
        st.session_state["pedidos_pipeline"] = pipeline_model
        st.session_state["pedidos_lr_model"] = lr_model

        st.success("‚úÖ Modelo entrenado correctamente.")

    if "pedidos_resultados" in st.session_state:
        resultados = st.session_state["pedidos_resultados"]
        res = resultados["lr"]

        st.markdown("### üìà Resultados del modelo: **Regresi√≥n Log√≠stica**")

        c1, c2, c3= st.columns(3)
        c1.metric("Accuracy (¬øQu√© tantas notas clasifica bien el modelo?)", f"{res['accuracy']*100:.2f}%")
        c2.metric("F1-score (¬øQu√© tan equilibrada es la calidad de la clasificaci√≥n?)", f"{res['f1']:.3f}")
        c3.metric("Registros train/test", f"{res['num_train']} / {res['num_test']}")

        st.markdown("#### üîÅ Matriz de confusi√≥n para datos test")
        st.dataframe(res["confusion"])

        # res["confusion"] puede ser Spark DF o pandas DF
        conf = res["confusion"]
        try:
            pdf_conf = conf.toPandas()
        except AttributeError:
            pdf_conf = conf.copy()

        # Aseguramos nombres coherentes
        pdf_conf.columns = ["real", "prediccion", "cantidad"]

        # 1) Agrupar por (real, prediccion) para evitar duplicados
        pdf_agg = (
            pdf_conf
            .groupby(["real", "prediccion"], as_index=False)["cantidad"]
            .sum()
        )

        # 2) Etiquetas legibles
        map_real = {
            0: "Real: 0 (no gener√≥ pedido)",
            1: "Real: 1 (s√≠ gener√≥ pedido)",
        }
        map_pred = {
            0: "Predicho: 0 (no pedido)",
            1: "Predicho: 1 (pedido)",
        }

        pdf_agg["real_label"] = pdf_agg["real"].map(map_real)
        pdf_agg["pred_label"] = pdf_agg["prediccion"].map(map_pred)

        # 3) Pivot a matriz 2x2
        matriz = (
            pdf_agg
            .pivot(index="real_label", columns="pred_label", values="cantidad")
            .fillna(0)
        )

        fig_cm = px.imshow(
            matriz,
            text_auto=True,
            color_continuous_scale="Blues",
            labels=dict(
                x="Predicci√≥n del modelo",
                y="Etiqueta real",
                color="Cantidad"
            ),
            title="Matriz de confusi√≥n ‚Äì modelo de predicci√≥n de pedidos"
        )
        fig_cm.update_layout(xaxis_side="top")

        st.plotly_chart(fig_cm, use_container_width=True)

        st.markdown(
            """
            <p style='font-size: 0.85rem; color: gray;'>
            La matriz de confusi√≥n permite evaluar qu√© tan bien el modelo distingue entre gestiones que generan pedido y las que no.<br>
            ‚Ä¢ El modelo clasifica correctamente la mayor parte de los casos sin pedido (‚âà34.9k aciertos).<br>
            ‚Ä¢ Tambi√©n identifica de forma adecuada los pedidos reales (‚âà22.9k aciertos).<br>
            ‚Ä¢ Los errores de predicci√≥n se mantienen moderados frente al volumen total analizado.<br>
            </p>
            """,
            unsafe_allow_html=True
        )

        # -------- PRUEBA EN VIVO DEL MODELO DE PEDIDOS --------
        st.markdown("---")
        st.subheader("‚úçÔ∏è Prueba en vivo del modelo de pedidos")

        st.caption("Configura una gesti√≥n hipot√©tica y el modelo estimar√° la probabilidad de que genere un pedido.")

        if (
            "pedidos_pipeline" not in st.session_state
            or "pedidos_lr_model" not in st.session_state
        ):
            st.warning("Primero entrena el modelo con el bot√≥n de arriba.")
        else:
            pipeline_model = st.session_state["pedidos_pipeline"]
            lr_model = st.session_state["pedidos_lr_model"]

            with st.form("form_pred_pedido"):
                col1, col2 = st.columns(2)
                with col1:
                    medio = st.selectbox("Medio de contacto", ["llamada", "whatsapp"])
                    resultado_asesor = st.selectbox(
                        "Resultado del asesor",
                        ["interesado", "no_interesado"]
                    )
                with col2:
                    hora = st.slider("Hora del d√≠a", min_value=9, max_value=21, value=12)

                submitted = st.form_submit_button("Predecir probabilidad de pedido")

                if submitted:
                    # üîπ Solo simulamos fecha ficticia para generar el datetime
                    fecha_hora_str = f"2025-01-01 {hora:02d}:00:00"

                    pred_clase, prob_pedido = predecir_pedido(
                        pipeline_model=pipeline_model,
                        modelo=lr_model,
                        spark=get_spark(),
                        medio=medio,
                        resultado_asesor=resultado_asesor,
                        fecha_hora_str=fecha_hora_str,
                    )

                    etiqueta = "S√≠ generar√≠a pedido" if pred_clase == 1 else "No generar√≠a pedido"

                    st.success(f"Predicci√≥n: **{etiqueta}**")
                    st.metric("Probabilidad estimada de pedido", f"{prob_pedido*100:.2f}%")

                    # üìå Simulaci√≥n por hora (sin usar fecha real)
                    horas = list(range(9, 22))
                    probs_horas = []

                    for h in horas:
                        fecha_hora_simulada = f"2025-01-01 {h:02d}:00:00"

                        _, prob_h = predecir_pedido(
                            pipeline_model=pipeline_model,
                            modelo=lr_model,
                            spark=get_spark(),
                            medio=medio,
                            resultado_asesor=resultado_asesor,
                            fecha_hora_str=fecha_hora_simulada
                        )
                        probs_horas.append(prob_h)

                    if not probs_horas:
                        st.warning("No se pudo calcular la probabilidad por hora.")
                    else:
                        probs_horas_np = np.array(probs_horas)
                        idx_orden = probs_horas_np.argsort()[::-1]
                        top_k = 3
                        mejores_idx = idx_orden[:top_k]
                        mejores_horas = [horas[i] for i in mejores_idx]
                        mejores_probs = [probs_horas_np[i] for i in mejores_idx]

                        st.markdown("### üß≠ Recomendaci√≥n de horario:")

                        texto_mejores = ", ".join(
                            [f"{h:02d}:00 (~{p*100:.1f}%)" for h, p in zip(mejores_horas, mejores_probs)]
                        )

                        st.info(
                            f"Las horas con **mayor probabilidad de generar pedido** son: {texto_mejores}.<br>"
                            f"Seleccionaste **{hora:02d}:00**, con una probabilidad estimada de "
                            f"**{prob_pedido*100:.1f}%**."
                        )

                        # Mejoras sugeridas
                        st.subheader("üí° ¬øC√≥mo podr√≠a mejorar esta probabilidad?")

                        otro_medio = "whatsapp" if medio == "llamada" else "llamada"
                        _, prob_otro_medio = predecir_pedido(
                            pipeline_model=pipeline_model,
                            modelo=lr_model,
                            spark=get_spark(),
                            medio=otro_medio,
                            resultado_asesor=resultado_asesor,
                            fecha_hora_str=fecha_hora_str,
                        )

                        recomendaciones = []

                        mejor_hora = mejores_horas[0]
                        mejor_prob = mejores_probs[0]

                        if mejor_hora != hora and mejor_prob > prob_pedido + 0.03:
                            recomendaciones.append(
                                f"- Reagendar alrededor de **{mejor_hora:02d}:00** "
                                f"(probabilidad estimada: **{mejor_prob*100:.1f}%**)."
                            )

                        if prob_otro_medio > prob_pedido + 0.03:
                            recomendaciones.append(
                                f"- Cambiar a **{otro_medio}** puede aumentar la probabilidad "
                                f"a **{prob_otro_medio*100:.1f}%**."
                            )

                        if not recomendaciones:
                            st.success(
                                "La configuraci√≥n actual ya es bastante buena. "
                                "Puedes explorar el an√°lisis por hora para optimizar m√°s."
                            )
                        else:
                            st.markdown(
                                "Acciones que **podr√≠an aumentar la probabilidad de generar pedido**:"
                            )
                            for rec in recomendaciones:
                                st.markdown(rec)

    else:
        st.warning("Pulsa el bot√≥n para entrenar el modelo de predicci√≥n de pedidos.")



# ===============================
# P√ÅGINA: DASHBOARD Y CONCLUSIONES
# ===============================
elif page == "üìù Conclusiones":
    st.title("üìå Conclusiones")

    st.info("""
    1. **Gestiones y eficiencia:** En 2025 se realizaron 1 mill√≥n de gestiones, pero solo el 40% concluyen en pedido, lo que evidencia un amplio margen de mejora comercial.

    2. **Patr√≥n mensual:** Aunque las gestiones se mantienen estables, mayo destaca con el mayor n√∫mero de pedidos aun sin ser el mes m√°s activo. Importa m√°s la calidad de la gesti√≥n que el volumen.

    3. **Inter√©s del cliente:** La mayor√≠a se clasifica como no interesado, pero el comportamiento es estable. Esto refuerza que el inter√©s depende del contenido de la gesti√≥n y no del n√∫mero.

    4. **Medio vs categor√≠a:** Las llamadas son consistentemente m√°s efectivas que WhatsApp. La categor√≠a con mayor conversi√≥n es conectividad.  
    ‚Üí **Mejor combinaci√≥n: llamada + conectividad.**

    5. **Rendimiento de asesores:** Los mejores asesores generan ~1000 pedidos, mientras que los de menor desempe√±o rondan los ~550, pese a tener vol√∫menes similares. Hay oportunidad de replicar buenas pr√°cticas.

    6. **Modelo de predicci√≥n:** La regresi√≥n log√≠stica logra un 72% de accuracy, permitiendo estimar si una gesti√≥n terminar√° en pedido y en qu√© condiciones.

    7. **Modelo NLP:** El modelo NLP obtiene 92% de accuracy y detecta patrones ling√º√≠sticos que predicen el verdadero inter√©s del cliente, √∫til para entrenamiento y estandarizaci√≥n de notas.
    """)